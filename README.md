# ğŸ§  Early Alzheimerâ€™s Detection from Speech Patterns (NLP + ML)

### ğŸ” Project Overview
This project predicts early signs of **Alzheimerâ€™s disease** based on **speech patterns** â€” using both **linguistic** (text-based) and **acoustic** (MFCC) features.  
The system can take **user-typed input** like:  
> "Hi... umm... ho ar u..."  
and detect disfluency or irregular language patterns that may indicate cognitive decline.

Built with **Python, scikit-learn, XGBoost, LightGBM**, and **ensemble learning techniques**, this end-to-end workflow covers data preprocessing, model training, evaluation, and real-time prediction.

---

## âš™ï¸ Project Pipeline

| Step | Notebook | Description |
|------|-----------|--------------|
| 1ï¸âƒ£ | `01_Preprocessing.ipynb` | Data cleaning, feature engineering, PCA for linguistic features, MFCC stats |
| 2ï¸âƒ£ | `02_Model_Training.ipynb` | Ensemble + stacking model training and comparison |
| 3ï¸âƒ£ | `03_Evaluation_and_Prediction.ipynb` | Model evaluation and user text-based Alzheimerâ€™s prediction |

---

## ğŸ“˜ 1. Dataset Description

| Feature Group | Description |
|----------------|-------------|
| **duration_sec**, **chunk_count** | Basic speech metrics (length, segmentation) |
| **mfcc_1 â€“ mfcc_13** | Acoustic features (Mel-Frequency Cepstral Coefficients) |
| **linguistic_feat_1 â€“ linguistic_feat_50** | Text-based linguistic embeddings |
| **label** | Target variable â€” 0 = Healthy, 1 = Alzheimerâ€™s |

ğŸ“‚ Original dataset: `data/addetector_dataset.csv`  
ğŸ“‚ Cleaned dataset after preprocessing: `data/cleaned_addetector_dataset.csv`

---

## ğŸ§¹ 2. Preprocessing Highlights (`01_Preprocessing.ipynb`)

### ğŸ§© Key Steps:
- Removed nulls & duplicates  
- Scaled features using **StandardScaler**  
- **Linguistic Features â†’ PCA (Top 10 components)** to preserve semantic richness  
- **MFCC Features â†’ Mean, Std, Var** to capture tone dynamics  
- Train-test split (80â€“20 stratified)  

### ğŸ§¾ Output:
- Clean, reduced dataset â†’ `data/cleaned_addetector_dataset.csv`  
- Feature count reduced from 66 â†’ 18 (optimized for interpretability)  

---

## ğŸ¤– 3. Model Training (`02_Model_Training.ipynb`)

### ğŸ§  Models Used:
| Type | Model | Purpose |
|------|--------|----------|
| Base | Logistic Regression | Lightweight baseline |
| Base | Random Forest | Robust, interpretable ensemble |
| Base | XGBoost | Gradient-boosted high performer |
| Base | LightGBM | Efficient gradient boosting |
| Ensemble | Voting Classifier | Averages model probabilities |
| Ensemble | Stacking Classifier | Meta-learner improves final accuracy |

### âš™ï¸ Training Setup
- Used **class_weight='balanced'** to handle class imbalance  
- Evaluated models with: Accuracy, Precision, Recall, F1, ROC-AUC  
- Saved **best model automatically** to `models/<best_model>_best.pkl`  

### ğŸ“Š Example Results

| Model | Accuracy | F1 Score | ROC-AUC |
|--------|-----------|-----------|----------|
| Logistic Regression | 0.68 | 0.60 | 0.71 |
| Random Forest | 0.73 | 0.65 | 0.77 |
| XGBoost | 0.76 | 0.70 | 0.80 |
| LightGBM | 0.77 | 0.72 | 0.81 |
| **Voting Ensemble** | 0.80 | 0.74 | 0.84 |
| **Stacking Ensemble** | **0.83** | **0.78** | **0.88** |

ğŸ§¾ Final Model: `models/Stacking_Ensemble_best.pkl`  
ğŸ“ˆ Metrics: `results/metrics.json`

---

## ğŸ’¬ 4. Prediction & Evaluation (`03_Evaluation_and_Prediction.ipynb`)

### âœï¸ Live Text Prediction
The user can input text such as:
```
Hi... um... I forget what I was saying...
```
The system extracts simplified linguistic signals and predicts:
```
ğŸ§  Alzheimerâ€™s Detected
Confidence: 0.82
```

### ğŸ§© Linguistic Cues Extracted:
- Word count  
- Unique word ratio  
- Pause count (â€œ...â€)  
- Average word length  
- Readability score  
- Derived linguistic PCA embeddings  

### ğŸ“Š Model Evaluation
- Confusion Matrix visualization  
- ROC Curve & AUC  
- Performance barplots (Accuracy, F1, Recall, Precision)  

---

## ğŸ§© 5. Explainability (Optional)
Use **SHAP** to explain model behavior and feature importance:
```python
import shap
explainer = shap.Explainer(model, X)
shap_values = explainer(X)
shap.summary_plot(shap_values, X)
```

Helps visualize which linguistic or acoustic cues most influence Alzheimerâ€™s detection.

---

## ğŸ“¦ 6. Folder Structure

```
AlzheimerSpeechDetection/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ addetector_dataset.csv
â”‚   â””â”€â”€ cleaned_addetector_dataset.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Preprocessing.ipynb
â”‚   â”œâ”€â”€ 02_Model_Training.ipynb
â”‚   â”œâ”€â”€ 03_Evaluation_and_Prediction.ipynb
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ Stacking_Ensemble_best.pkl
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics.json
â”‚   â””â”€â”€ confusion_matrix.png
â”‚
â””â”€â”€ README.md
```

---

## ğŸ§  7. Key Learnings
âœ… PCA preserved linguistic expressiveness  
âœ… MFCC statistics captured subtle tone variations  
âœ… Stacking ensembles boosted F1 and recall performance  
âœ… Text-based simulation provided a deployable prototype for real-world scenarios  

---

## ğŸ§© 8. Future Improvements
- Integrate **real audio preprocessing** (using `librosa`)  
- Add **speech-to-text (ASR)** pipeline (Google, Whisper, or Vosk)  
- Enhance **linguistic feature extraction** using transformer models (BERT-based embeddings)  
- Deploy app publicly on **Hugging Face Spaces** or a lightweight web framework  

---

## ğŸ‘¨â€ğŸ’» Author
- **Developer:** [Your Name]  
- **Tools Used:** Python, scikit-learn, XGBoost, LightGBM, SHAP  

---

### ğŸ¯ Final Output Example

| Input Text | Prediction | Confidence |
|-------------|-------------|-------------|
| Hi how are you today? | âœ… Healthy Speech Pattern | 0.15 |
| Hi... umm... ho ar u... hmm I forget | ğŸ§  Alzheimerâ€™s Detected | 0.82 |

---

**âœ… Final Deliverables:**
- Trained ensemble Alzheimerâ€™s classifier  
- Text-based predictor  
- Documentation & notebooks ready for submission or demo  

---

 
